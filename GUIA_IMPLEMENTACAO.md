# üêç Guia de Implementa√ß√£o: Backend Python para IA Financeira

## Vis√£o Geral

Este √© o m√≥dulo backend em Python para o sistema de IA financeira da Aura. O m√≥dulo processa requisi√ß√µes de assistentes de voz (como Alexa) e gera respostas inteligentes usando m√∫ltiplos provedores de IA.

## Caracter√≠sticas Principais

‚úÖ **Suporte a M√∫ltiplos Provedores de IA**
- Google Gemini
- OpenAI GPT
- Arquitetura modular permite adicionar novos provedores facilmente

‚úÖ **Sistema de Logging Completo**
- Todas as intera√ß√µes s√£o registradas
- Logs estruturados em JSON
- N√≠veis de log configur√°veis

‚úÖ **Configura√ß√£o Flex√≠vel**
- Vari√°veis de ambiente
- Arquivos de configura√ß√£o JSON
- Valores padr√£o sensatos

‚úÖ **Processamento Ass√≠ncrono**
- Suporte completo a async/await
- Alta performance e escalabilidade

‚úÖ **Tratamento de Erros Robusto**
- Exce√ß√µes customizadas
- Fallback entre provedores
- Logs detalhados de erros

## Estrutura do Projeto

```
aura-intelligent-answers-module/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ aura_ia/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py           # M√≥dulo principal
‚îÇ       ‚îú‚îÄ‚îÄ core/                 # Componentes principais
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ ai_provider.py    # Interface base para provedores
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ logger.py         # Sistema de logging
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ processor.py      # Processador de requisi√ß√µes
‚îÇ       ‚îú‚îÄ‚îÄ providers/            # Implementa√ß√µes de provedores
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ gemini_provider.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ gpt_provider.py
‚îÇ       ‚îî‚îÄ‚îÄ utils/                # Utilit√°rios
‚îÇ           ‚îú‚îÄ‚îÄ __init__.py
‚îÇ           ‚îú‚îÄ‚îÄ config.py         # Gerenciamento de configura√ß√£o
‚îÇ           ‚îî‚îÄ‚îÄ exceptions.py     # Exce√ß√µes customizadas
‚îú‚îÄ‚îÄ tests/                        # Testes unit√°rios
‚îú‚îÄ‚îÄ logs/                         # Logs de intera√ß√µes (criado automaticamente)
‚îú‚îÄ‚îÄ main.py                       # Ponto de entrada para testes
‚îú‚îÄ‚îÄ requirements.txt              # Depend√™ncias Python
‚îú‚îÄ‚îÄ .env.example                  # Exemplo de configura√ß√£o
‚îú‚îÄ‚îÄ config.example.json           # Exemplo de config JSON
‚îî‚îÄ‚îÄ README.md                     # Documenta√ß√£o
```

## Instala√ß√£o

### 1. Clonar o Reposit√≥rio

```bash
git clone https://github.com/DannyahIA/aura-intelligent-answers-module.git
cd aura-intelligent-answers-module
```

### 2. Criar Ambiente Virtual (Recomendado)

```bash
python -m venv venv

# No Linux/Mac:
source venv/bin/activate

# No Windows:
venv\Scripts\activate
```

### 3. Instalar Depend√™ncias

```bash
pip install -r requirements.txt
```

### 4. Configurar API Keys

#### Op√ß√£o 1: Vari√°veis de Ambiente

Copie o arquivo de exemplo e configure suas chaves:

```bash
cp .env.example .env
```

Edite o arquivo `.env` e adicione suas chaves de API:

```env
GEMINI_API_KEY=sua_chave_aqui
OPENAI_API_KEY=sua_chave_aqui
DEFAULT_AI_PROVIDER=gemini
```

Carregue as vari√°veis de ambiente:

```bash
# Usando python-dotenv (recomendado)
pip install python-dotenv
```

#### Op√ß√£o 2: Arquivo de Configura√ß√£o JSON

```bash
cp config.example.json config.json
```

Edite `config.json` e adicione suas configura√ß√µes.

## Uso B√°sico

### 1. Teste R√°pido via CLI

```bash
python main.py
```

### 2. Uso Program√°tico

```python
import asyncio
from aura_ia.core.processor import RequestProcessor
from aura_ia.utils.config import Config

async def exemplo():
    # Inicializar processador
    config = Config()  # Usa vari√°veis de ambiente
    processor = RequestProcessor(config)
    
    # Processar requisi√ß√£o
    resultado = await processor.process_request(
        request="Quais s√£o os melhores investimentos para iniciantes?",
        context={
            "user_type": "investor",
            "expertise_level": "beginner"
        }
    )
    
    # Usar resposta
    if resultado["success"]:
        print(f"Resposta: {resultado['response']}")
    else:
        print(f"Erro: {resultado['error']}")

# Executar
asyncio.run(exemplo())
```

### 3. Com Hist√≥rico de Conversa

```python
resultado = await processor.process_request(
    request="E quanto preciso investir?",
    context={"user_type": "investor"},
    conversation_history=[
        {"role": "user", "content": "Quais s√£o os melhores investimentos?"},
        {"role": "assistant", "content": "Para iniciantes, recomendo..."}
    ]
)
```

### 4. Especificar Provedor

```python
# Usar Gemini
resultado = await processor.process_request(
    request="Explique diversifica√ß√£o de portf√≥lio",
    provider_name="gemini"
)

# Usar GPT
resultado = await processor.process_request(
    request="Explique diversifica√ß√£o de portf√≥lio",
    provider_name="gpt"
)
```

## API Reference

### RequestProcessor

Processador principal de requisi√ß√µes.

#### `__init__(config: Optional[Config] = None)`

Inicializa o processador.

#### `async process_request(request: str, context: Optional[Dict] = None, conversation_history: Optional[List] = None, provider_name: Optional[str] = None) -> Dict`

Processa uma requisi√ß√£o e retorna resposta.

**Par√¢metros:**
- `request`: String com a pergunta/requisi√ß√£o do usu√°rio
- `context`: Dicion√°rio com contexto adicional (opcional)
- `conversation_history`: Lista com hist√≥rico de mensagens (opcional)
- `provider_name`: Nome do provedor espec√≠fico a usar (opcional)

**Retorna:**
```python
{
    "success": bool,
    "response": str,  # Se success=True
    "error": str,     # Se success=False
    "provider": str,
    "request": str
}
```

#### `get_available_providers() -> List[str]`

Retorna lista de provedores dispon√≠veis.

#### `switch_default_provider(provider_name: str) -> bool`

Altera o provedor padr√£o.

### Config

Gerenciamento de configura√ß√£o.

#### `__init__(config_path: Optional[str] = None)`

Inicializa configura√ß√£o (de arquivo ou ambiente).

#### `get(key: str, default: Any = None) -> Any`

Obt√©m valor de configura√ß√£o (suporta nota√ß√£o com pontos).

#### `set(key: str, value: Any) -> None`

Define valor de configura√ß√£o.

#### `get_provider_config(provider_name: str) -> Dict`

Obt√©m configura√ß√£o de um provedor espec√≠fico.

## Configura√ß√£o Avan√ßada

### Par√¢metros dos Provedores

```python
from aura_ia.core.ai_provider import AIProviderConfig
from aura_ia.providers.gemini_provider import GeminiProvider

config = AIProviderConfig(
    api_key="sua_chave",
    model="gemini-pro",
    temperature=0.7,      # Criatividade (0.0-1.0)
    max_tokens=2048,      # M√°ximo de tokens na resposta
    additional_params={}  # Par√¢metros adicionais
)

provider = GeminiProvider(config)
```

### N√≠veis de Log

- `DEBUG`: Informa√ß√µes detalhadas para diagn√≥stico
- `INFO`: Confirma√ß√£o de que tudo est√° funcionando
- `WARNING`: Indica√ß√£o de algo inesperado
- `ERROR`: Erro que impediu alguma funcionalidade
- `CRITICAL`: Erro grave que pode impedir o sistema de funcionar

```python
# Via ambiente
LOG_LEVEL=DEBUG

# Via c√≥digo
logger = InteractionLogger(log_level="DEBUG")
```

## Adicionando Novos Provedores

1. Crie um novo arquivo em `src/aura_ia/providers/`
2. Implemente a classe herdando de `AIProvider`
3. Implemente os m√©todos abstratos:
   - `generate_response()`
   - `get_provider_name()`
   - `is_available()`

Exemplo:

```python
from ..core.ai_provider import AIProvider, AIProviderConfig

class NovoProvider(AIProvider):
    def __init__(self, config: AIProviderConfig):
        super().__init__(config)
        # Inicializar cliente
    
    async def generate_response(self, prompt, context=None, conversation_history=None):
        # Implementar gera√ß√£o de resposta
        pass
    
    def get_provider_name(self) -> str:
        return "novo_provider"
    
    def is_available(self) -> bool:
        return True  # Verificar disponibilidade
```

## Integra√ß√£o com Alexa

Para integrar com Alexa, processe as requisi√ß√µes da seguinte forma:

```python
from aura_ia.core.processor import RequestProcessor

processor = RequestProcessor()

async def alexa_handler(event, context):
    # Extrair requisi√ß√£o da Alexa
    user_request = event["request"]["intent"]["slots"]["question"]["value"]
    
    # Processar com Aura IA
    resultado = await processor.process_request(user_request)
    
    # Retornar resposta para Alexa
    return {
        "version": "1.0",
        "response": {
            "outputSpeech": {
                "type": "PlainText",
                "text": resultado["response"] if resultado["success"] else "Desculpe, ocorreu um erro."
            }
        }
    }
```

## Logs e Monitoramento

Todos os logs s√£o salvos em `logs/interactions.log` (configur√°vel).

### Formato de Log de Intera√ß√£o

```json
{
  "timestamp": "2025-01-15T10:30:00.000000",
  "request": "Qual √© a melhor estrat√©gia de investimento?",
  "response": "Para iniciantes, recomendo...",
  "provider": "gemini",
  "metadata": {
    "context": {"user_type": "investor"},
    "has_history": false
  }
}
```

### Formato de Log de Erro

```json
{
  "timestamp": "2025-01-15T10:30:00.000000",
  "error_type": "provider_error",
  "error_message": "API key inv√°lida",
  "details": {
    "provider": "gemini"
  }
}
```

## Testes

Execute os testes unit√°rios:

```bash
pytest tests/
```

Com cobertura:

```bash
pytest --cov=src/aura_ia tests/
```

## Troubleshooting

### Erro: "No AI provider available"

**Causa:** Nenhuma chave de API configurada.

**Solu√ß√£o:** Configure pelo menos uma chave de API (GEMINI_API_KEY ou OPENAI_API_KEY).

### Erro: "Package not installed"

**Causa:** Depend√™ncias n√£o instaladas.

**Solu√ß√£o:**
```bash
pip install -r requirements.txt
```

### Provider n√£o funciona

**Verificar:**
1. Chave de API est√° correta
2. Modelo especificado existe
3. Quota da API n√£o foi excedida
4. Conex√£o com internet est√° funcionando

## Performance

- **Lat√™ncia**: ~1-3 segundos por requisi√ß√£o (dependendo do provedor)
- **Throughput**: Limitado pela API do provedor
- **Mem√≥ria**: ~50-100MB (vari√°vel com hist√≥rico de conversa)

## Seguran√ßa

‚ö†Ô∏è **IMPORTANTE:**

1. **NUNCA** commite chaves de API no reposit√≥rio
2. Use vari√°veis de ambiente ou arquivos de configura√ß√£o n√£o versionados
3. Adicione `.env` e `config.json` ao `.gitignore`
4. Rotacione chaves regularmente
5. Use diferentes chaves para dev/staging/production

## Contribuindo

1. Fork o reposit√≥rio
2. Crie uma branch para sua feature (`git checkout -b feature/nova-feature`)
3. Commit suas mudan√ßas (`git commit -am 'Adiciona nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

## Licen√ßa

MIT License - veja [LICENSE](LICENSE) para detalhes.

## Suporte

Para quest√µes e suporte:
- Abra uma issue no GitHub
- Consulte a documenta√ß√£o
- Entre em contato com a equipe

## Roadmap

- [ ] Suporte a mais provedores (Claude, Cohere, etc.)
- [ ] Cache de respostas para otimiza√ß√£o
- [ ] M√©tricas e analytics
- [ ] API REST para integra√ß√£o externa
- [ ] Interface web para testes
- [ ] Suporte a streaming de respostas
- [ ] Fine-tuning de modelos
- [ ] Suporte a multimodalidade (imagens, voz)

## Changelog

### v0.1.0 (2025-01-15)
- ‚ú® Implementa√ß√£o inicial
- ‚úÖ Suporte a Gemini e GPT
- ‚úÖ Sistema de logging
- ‚úÖ Configura√ß√£o flex√≠vel
- ‚úÖ Processamento ass√≠ncrono
- ‚úÖ Documenta√ß√£o completa
